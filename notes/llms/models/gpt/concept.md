# GPT

## Definition

GPT - Generative Pre-trained Transformer.

## Model Architecture

A stack of Transformer blocks, where each block is a stack of a self-attention layer and a feed-forward layer.

## Training Objectives

Predict next token in a sequence.

## Context Direction

Unidirectional.
